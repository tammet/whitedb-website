<!DOCTYPE html>
<html lang="en">
<head itemscope>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<meta name="description" content="A fast lightweight NoSQL shared memory database library written in C">
<meta name="author" content="Tanel Tammet, Priit Järv">
<meta name="keywords" content="database, library, main memory, shared memory, speed, NoSQL" /> 

<meta itemprop="itemtype" content="http://schema.org/SoftwareApplication" />
<meta itemprop="name" content="WhiteDB" />
<meta itemprop="description" content="WhiteDB is a fast, lightweight NoSQL shared memory database library written in C." />
<meta itemprop="url" content="http://www.whitedb.org" />
<meta itemprop="operatingSystems" content="Linux, Windows" />
<meta itemprop="softwareApplicationCategory" content="DeveloperApplication" />

<meta property="og:title" content="WhiteDB"/> 
<meta property="og:url" content="http://www.whitedb.org"/> 
<meta property="og:site_name" content="WhiteDB"/> 
<meta property="og:type" content="website"/>
<meta property="og:description" content="A fast lightweight NoSQL shared memory database library written in C."/>
<meta property="fb:admins" content="tanel.tammet"/>

<link rel="shortcut icon" href="img/logo2.png">

<title>Whitedb</title>
<!--
<link href='http://fonts.googleapis.com/css?family=Roboto:300' rel='stylesheet' type='text/css'>
-->
<!-- Bootstrap core CSS -->
<link href="css/bootstrap.min.css" rel="stylesheet">
<!-- Custom styles for this template -->
<link href="css/wdb.css" rel="stylesheet">
<!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!--[if lt IE 9]>
  <script src="js/html5shiv.js"></script>
  <script src="js/respond.min.js"></script>
<![endif]-->
<!--  
<style type="text/css"></style>
-->
<!-- <script src="js/jquery.js"></script> -->
<script src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script>

function setleftmenu() {
  var d;
  d=$("#maincontainer").offset();
  if (d && d.left && d.left>10) {
    $("#sidemenu").css("left",""+d.left-300);    
  }    
}

function shortenmenu(){
 $('#sidemenu a').each(function(){
    $(this).text($(this).text().substring(2));
 });
}

/*
function onscroll() {
  var d2;
  d2=window.pageYOffset;
  //console.log(d2);
  if (!d2) $("#sidemenu").css("top",""+84);
  else {
    if (d2>74) {
      $("#sidemenu").css("top","10");
    } else {
      $("#sidemenu").css("top",""+84-d2);
    }  
  }      
}
*/

$(document).ready(function(){  
  shortenmenu();
  setleftmenu();
	$("dt").click(function(){
		if(!$(this).hasClass("xopen")) {
      $(this).addClass("xopen");
      $(this).next().find("dl").slideDown(400);
			//$(this).next().find("dl").css("display","block");      
		} else {
      $(this).removeClass("xopen");
      $(this).next().find("dl").slideUp(400);
      //$(this).next().find("dl").css("display","none");      
    }        
	});
  $(window).resize(function() {
    setleftmenu();
  });
})

</script>
</head>

<body>

<div id="fb-root"></div>

<div class="navbar navbar-inverse navbar-static-top" style="background-color: #333333;">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"><img class="logo" src="img/logo1.png"/>WhiteDB</a>
    </div>
    <div class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dummy"><a href="index.html">Home</a></li>        
        <li class="dummy"><a href="tutorial.html">Tutorial</a></li>
        <li class="dummy"><a href="speed.html">Speed</a></li>
        <!-- <li class="dummy"><a href="scenarios.html">Scenarios</a></li> -->
        <li class="dummy"><a href="c_api.html">C API</a></li>        
        <li class="dummy"><a href="python_api.html">Python</a></li> 
        <li class="dummy"><a href="tools.html">Tools</a></li>
        <li class="dummy"><a href="download.html">Download</a></li>
        <li class="dummy"><a href="install.html">Install</a></li>
        <li class="dummy"><a href="licence.html">Licence</a></li>
        <li class="dummy"><a href="contact.html">Contact</a></li>        
      </ul>
    </div><!--/.navbar-collapse -->
  </div>
</div>

<!-- content after titlebar -->

<!-- jumbotron for a primary message  -->

<div class="jumbotron" id="jumbotron">
  <div class="container" style="text-align: left">
    <h1 class="jumbotron_title">Tools</h1>
    <p class="jumbotron_caption">For command line and json
    </p>
  </div>  
</div>

<!-- sidemenu for large screens -->

<div id="sidemenu" class="hidden-print sidemenu" role="complementary">
<div class="isidemenu">  
<h3 class="menutitle">Contents</h3>
<dl class="toc"><dt><span class="section"><a href="#_wgdb_general_database_management">1. wgdb - general database management</a></span></dt><dd><dl><dt><span class="section"><a href="#_importing_and_exporting_data">1.1. Importing and exporting data</a></span></dt><dt><span class="section"><a href="#_memory_dumps_and_journal_logs">1.2. Memory dumps and journal logs</a></span></dt></dl></dd><dt><span class="section"><a href="#_dserve_simple_rest_queries_with_json">2. dserve - simple REST queries with json</a></span></dt><dd><dl><dt><span class="section"><a href="#_query_by_field_values">2.1. Query by field values</a></span></dt><dt><span class="section"><a href="#_query_by_record_id_s">2.2. Query by record id-s</a></span></dt><dt><span class="section"><a href="#_good_to_know">2.3. Good to know</a></span></dt></dl></dd></dl>
</div>
</div>

<!-- main content -->

<div class="container" id="maincontainer">
  <div class="row">
     <div class="col-md-12 wblock wblock1">
      <div class="wiblock wiblock_full">      
<div class="toc">
<dl class="toc"><dt><span class="section"><a href="#_wgdb_general_database_management">1. wgdb - general database management</a></span></dt><dd><dl><dt><span class="section"><a href="#_importing_and_exporting_data">1.1. Importing and exporting data</a></span></dt><dt><span class="section"><a href="#_memory_dumps_and_journal_logs">1.2. Memory dumps and journal logs</a></span></dt></dl></dd><dt><span class="section"><a href="#_dserve_simple_rest_queries_with_json">2. dserve - simple REST queries with json</a></span></dt><dd><dl><dt><span class="section"><a href="#_query_by_field_values">2.1. Query by field values</a></span></dt><dt><span class="section"><a href="#_query_by_record_id_s">2.2. Query by record id-s</a></span></dt><dt><span class="section"><a href="#_good_to_know">2.3. Good to know</a></span></dt></dl></dd></dl>
</div> <!-- inner toc end -->
<div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="_wgdb_general_database_management"></a>1. wgdb - general database management</h2></div></div></div><p>This is a simple command-line utility that allows creating and freeing
a database, dump, import, run some tests and more.</p><p>Usage:</p><pre class="literallayout">wgdb [shmname] &lt;command&gt; [command arguments]</pre><p>The shared memory name identifies the database to use and is an arbitrary
numeric value. If it is omitted, the default ("1000") will be used.</p><p>Commands commonly available:</p><pre class="literallayout">help (or "-h") - display this text.
version (or "-v") - display libwgdb version.
free - free shared memory.
export [-f] &lt;filename&gt; - write memory dump to disk
      (-f: force dump even if unable to get lock)
import [-l] &lt;filename&gt; - read memory dump from disk. Overwrites  existing
      memory contents (-l: enable logging after import).
exportcsv &lt;filename&gt; - export data to a CSV file.
importcsv &lt;filename&gt; - import data from a CSV file.
replay &lt;filename&gt; - replay a journal file.
info - print information about the memory database.
add &lt;value1&gt; .. - store data row (only int or str recognized)
select &lt;number of rows&gt; [start from] - print db contents.
query &lt;col&gt; "&lt;cond&gt;" &lt;value&gt; .. - basic query.
del &lt;col&gt; "&lt;cond&gt;" &lt;value&gt; .. - like query. Matching rows are deleted from database.
createindex &lt;column&gt; - create ttree index.
createhash &lt;columns&gt; - create hash index (JSON support).
dropindex &lt;index id&gt; - delete an index.
listindex - list all indexes in database.
server [-l] [size b] - provide persistent shared memory for other processes (Windows).
       (-l: enable logging in the database).
create [-l] [size] - create empty db of given size (non-Windows).
       (-l: enable logging in the database,
       mode: segment permissions (octal)).</pre><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="_importing_and_exporting_data"></a>1.1. Importing and exporting data</h3></div></div></div><p>Data may be exported to and imported from text files. This provides a way
to exchange data between WhiteDB on different platforms or other data sources.
The simplest format that is always available is CSV (comma separated values).</p><p>Since there is no straightforward mapping between most of WhiteDB types and
the CSV format and as CSV is not standardized, only limited support for
data types is available. The following data types are recognized when
importing from CSV:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">
NULL - empty string
</li><li class="listitem">
int - plain integer
</li><li class="listitem">
double - floating point number in fixed decimal notation
</li><li class="listitem">
date - ISO8601 date
</li><li class="listitem">
time - ISO8601 time+fractions of second.
</li><li class="listitem">
string - input data that does not match the above types
</li></ul></div><p>The field separator is <span class="emphasis"><em>,</em></span> (comma). The decimal point separator is <span class="emphasis"><em>.</em></span> (dot).</p><p>WhiteDB may also provide RDF (if libraptor is available) and JSON (ongoing
development, undocumented) support.</p></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="_memory_dumps_and_journal_logs"></a>1.2. Memory dumps and journal logs</h3></div></div></div><p>In the default configuration, WhiteDB runs in shared memory only. There
are two methods of providing data persistence: memory dumps, which are
snapshots of the current database contents and journal logs which contain
incremental updates to the database contents. Logs are only available
if the database is configured with the <code class="literal">./configure --enable-logging</code>
option and need to be explicitly enabled.</p><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="_managing_memory_dumps"></a>Managing memory dumps</h4></div></div></div><p>A memory dump is the memory image of a WhiteDB database, saved into a file.
It stores everything except concurrency control and journal file metadata.
Images are not compatible between systems of different endianness or word
size (the most common case would probably be 32-bit vs 64-bit systems).
Also, different versions of the database library may use different format
for the memory image, therefore WhiteDB automatically refuses to import
an image made with a different library version.</p><p>Type <code class="literal">wgdb -v</code> to list the compatibility information of the database
library. It will display something like this:</p><pre class="literallayout">libwgdb version: 0.7.0
byte order: little endian
compile-time features:
64-bit encoded data: yes
queued locks: yes
chained nodes in T-tree: yes
record backlinking: yes
child databases: no
index templates: yes</pre><p>Memory dumps are suitable for creating snapshots of the database for
backup purposes. Type</p><pre class="literallayout">wgdb export imagename.bin</pre><p>to create a backup of the current database (since the shared memory name
was omitted, the <code class="literal">wgdb</code> utility will use "1000" by default).</p><pre class="literallayout">wgdb import imagename.bin</pre><p>Will restore the image from disk. It will completely overwrite the current
memory contents. Note that if there is an existing memory segment, it needs
to be large enough to fit the image. Otherwise the import will fail with an
error message (and the shared memory segment will not be modified).</p><p>If the <code class="literal">wgdb</code> tool is unable to access the memory image (for example, due
to a programming error that causes the database to become permanently locked),
a "rescue" dump can be created with</p><pre class="literallayout">wgdb export -f rescue.bin</pre><p>Note however, that in such cases care must be taken, as it is unknown what
type of errors the image may contain.</p></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="_managing_journal_logs"></a>Managing journal logs</h4></div></div></div><p>Journal logs provide a way of keeping a continuous backup of the database.
All of the changes to the shared memory are logged incrementally and the
journal logs may be played back to repeat all of those changes, bringing
the database to the same state as it was at the time the log file ended.</p><p>To enable journal logging, use</p><pre class="literallayout">./configure --enable-logging --with-logdir=./logs</pre><p>during the building of the database. Replace <span class="emphasis"><em>./logs</em></span> with wherever you’d
like the library to store the journal files. This location and the names
of the journal files are not changeable during runtime due to security
reasons. If you do not specify the log directory, <span class="emphasis"><em>/tmp</em></span> (or <span class="emphasis"><em>\windows\temp</em></span>)
will be used by default, which may work for testing, but is probably
undesirable in the long term.</p><p>Journaling must be enabled at the time of database creation. To do this from
the command line, supply the <code class="literal">-l</code> switch to either the <code class="literal">wgdb create</code> command
or when importing an image with the <code class="literal">wgdb import</code> command. This will cause a
journal file to be created. It will be placed in <span class="emphasis"><em>logdir/wgdb.journal.shmname</em></span>
where shmname is the database name, for example, "1000". The journal is then
incrementally written, until one of the three things happens:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
A dump file is created, either by <code class="literal">wgdb export</code> or by calling the
    <code class="literal">wg_dump()</code> function
</li><li class="listitem">
A dump file is imported (again, by command line or API)
</li><li class="listitem">
A journal file is replayed.
</li></ol></div><p>In each of these cases, the current journal file is backed up, appending
<span class="emphasis"><em>.0</em></span> to its name (or <span class="emphasis"><em>.1</em></span>, if <span class="emphasis"><em>.0</em></span> already exists and so forth) and a fresh
journal file is started.</p><p>The first case can be considered normal usage, as it creates a snapshot of
the database. Since this snapshot contains everything that the journal has
logged up to this point, the journal is no longer necessary for recovery
and a fresh one will be used.</p><p>Importing the dump file will either be part of a recovery process or to
simply work with a new image. In either case, the previous journal has
become irrelevant to the current database contents, making it necessary
to start a new one.</p><p>Finally, a journal replay itself will be not logged in a journal. Therefore,
the database contents after the replay and the journal file that was in
use during the replay have become inconsistent, similarly than whan happens
with importing a memory dump. Generally, journal backups caused by these
recovery actions should be cleaned up or moved away. The user is expected
to handle this manually, case by case.</p></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="_journal_log_example"></a>Journal log example</h4></div></div></div><p>Assuming we use the <span class="emphasis"><em>./logs</em></span> directory to store the journal files and the
database has been compiled with journal support, let’s start by enabling the
journal and adding data to the database:</p><pre class="literallayout">wgdb create -l
wgdb 1011 add 1 2 3</pre><p>The contents of the <span class="emphasis"><em>./logs</em></span> directory will now be:</p><pre class="literallayout">-rw-rw-rw- 1 user group 27 Dec  7 22:00 wgdb.journal.1011</pre><p>And the contents of the database, by typing <code class="literal">wgdb 1011 select 10</code>:</p><pre class="literallayout">[1,2,3]</pre><p>Let’s create a memory dump of this database. Make sure you don’t have
<span class="emphasis"><em>example.bin</em></span> already, as it will be overwritten.</p><pre class="literallayout">wgdb 1011 export example.bin</pre><p>Now we have these log files:</p><pre class="literallayout">-rw-rw-rw- 1 user group  4 Dec  7 22:04 wgdb.journal.1011
-rw-rw-rw- 1 user group 27 Dec  7 22:00 wgdb.journal.1011.0</pre><p>Note that the original file received the suffix <span class="emphasis"><em>.0</em></span> and a new one was
created in it’s place. Let’s add more data:</p><pre class="literallayout">wgdb 1011 add Hello world</pre><p>The database now contains:</p><pre class="literallayout">[1,2,3]
["Hello","world"]</pre><p>Assume next that something destroyed our database. Try <code class="literal">wgdb 1011 free</code>.
We now know that we have a recent dump called <span class="emphasis"><em>example.bin</em></span> and some
journals:</p><pre class="literallayout">-rw-rw-rw- 1 user group 47 Dec  7 22:06 wgdb.journal.1011
-rw-rw-rw- 1 user group 27 Dec  7 22:00 wgdb.journal.1011.0</pre><p>The newest journal is what we’re interested in. However, <span class="strong"><strong>keep in mind</strong></span> that
importing the dump restarts the journal. Nothing will happen to our precious
log file, but in order to avoid confusion, let’s move it somewhere safe
first:</p><pre class="literallayout">mv -i ./logs/wgdb.journal.1011 ./logs/recover.me.1011</pre><p>Import the dump (note that the <span class="emphasis"><em>-l</em></span> switch is used to re-enable journaling so
that our updates will be logged again after we’ve completed the recovery):</p><pre class="literallayout">wgdb 1011 import -l example.bin</pre><p>Try to list the database contents (<code class="literal">wgdb 1011 select 10</code>):</p><pre class="literallayout">[1,2,3]</pre><p>Finally, recover the log:</p><pre class="literallayout">wgdb 1011 replay ./logs/recover.me.1011</pre><p>And the database contents after this will be</p><pre class="literallayout">[1,2,3]
["Hello","world"]</pre><p>We managed to restore our latest state of the database by first importing
the dump file, then replaying the journal file that was written after
the dump was created. If we would now continue to modify the database, the
state could be recovered by importing <span class="emphasis"><em>example.bin</em></span> and then replaying
<span class="emphasis"><em>recover.me.1011</em></span> and the latest journal file <span class="emphasis"><em>wgdb.journal.1011</em></span> in that
order.</p><p>The recovery process creates a number of intermediate journals which we
may now clean up by <code class="literal">rm ./logs/wgdb.journal.1011.?</code>. CAUTION: in this case,
we moved the log file that we cared about, away first. This is why this
command is safe to use here. In general, however, it is better to make
sure that the deleted log files do not contain anything not backed up
elsewhere. The easiest way would be to verify that the database is
healthy and create a fresh memory dump.</p></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="_an_automated_backup_procedure"></a>An automated backup procedure</h4></div></div></div><p>A reasonable procedure that helps keeping track of image dumps and
journals could be implemented with a following script:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
dump the memory segment into a file such as <span class="emphasis"><em>backup.YYYYMMDD.shmname.bin</em></span>
</li><li class="listitem">
check that the dump was successful
</li><li class="listitem">
move <span class="emphasis"><em>logdir/wgdb.journal.shmname.0</em></span> to <span class="emphasis"><em>journal.YYYYMMDD.shmname</em></span>
</li></ol></div><p>This way, <span class="emphasis"><em>logdir</em></span> always contains only the current journal. Assuming that
YYYYMMDD represents the current date, memory dumps and journals can be
archived and accessed by date. If recovery is needed, the database
can be restored from the latest image and the current journal
in <span class="emphasis"><em>logdir/wgdb.journal.shmname</em></span> (which should first be archived separately).
Any journal backups in <span class="emphasis"><em>logdir</em></span> should then be removed after the restore
is successful, to ensure that step 3. archives the correct journal file
next time.</p></div></div></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="_dserve_simple_rest_queries_with_json"></a>2. dserve - simple REST queries with json</h2></div></div></div><div class="note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><span class="label label-info">!</span></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>dserve is work in progress and not part of the whitedb distribution yet.</p></td></tr></table></div><p>This is a simple REST service tool taking a query described with cgi parameters
and printing json or csv output.</p><p><code class="literal">dserve</code> is useful both as a ready-made tool and as an example/template for making
your own tools for WhiteDB data handling.
<code class="literal">dserve</code> is not compiled by default. Find it under the Examples folder as a
single source file dserve.c, modify and compile yourself by doing:</p><pre class="literallayout">gcc dserve.c -o dserve -O2 -lwgdb</pre><p>Copy the resulting executable under the cgi folder of the Apache server.</p><p>You can use <code class="literal">dserve</code> as a cgi program taking a few GET parameters like this</p><pre class="literallayout">http://myserver.com/cgi-bin/dserve?op=search&amp;from=0&amp;count=5</pre><p>or as a command line program: on the command line simply pass the
urlencoded query string as a single argument, for example</p><pre class="literallayout">dserve 'op=search&amp;from=2&amp;count=3'</pre><p>This will print rows 2..4 of the database, like this:</p><pre class="screen">content-length: 110
content-type: application/json

[
[1,1.1,"a simple string",[10,[],"point to me"],"2013-10-24","23:17:36.68"],
[12,"an:uri",-2000],
[23,-12]
]</pre><p>Observe that the fourth field contains a pointer to another record,
printed as a sublist. The same example with a small addition:</p><pre class="literallayout">dserve 'op=search&amp;from=2&amp;count=3&amp;showid=yes'</pre><p>The added <code class="literal">showid=yes</code> parameter prepends automatic record id-s
(encoded offsets) to each record as a first element:</p><pre class="screen">content-length: 134
content-type: application/json

[
[23368,1,1.1,"a simple string",[23304,10,[],"point to me"],"2013-10-24","23:17:36.68"],
[23408,12,"an:uri",-2000],
[23432,23,-12]
]</pre><p>The third example asks for three first records with field 0 less than 20:</p><pre class="screen">dserve 'op=search&amp;field=0&amp;value=20&amp;compare=lessthan&amp;count=3'

content-length: 178
content-type: application/json

[
[10,[],"point to me"],
[0,0.1,"a simple string",[10,[],"point to me"],"2013-10-24","23:17:36.68"],
[1,1.1,"a simple string",[10,[],"point to me"],"2013-10-24","23:17:36.68"]
]</pre><p>Dserve does not facilitate adding or updating records in the
database. We may add such a cgi utility in the future, but anyway, it is
a good idea to write your own utilities which fit your own needs exactly.</p><p>Most of the dserve parameters are optional, i.e. have sensible defaults. Limits,
error messages etc are all configurable by changing the macro definitions at
the beginning of the C source.</p><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="_query_by_field_values"></a>2.1. Query by field values</h3></div></div></div><p>You have to indicate the field numbers and the values
to compare the contents of these fields with.
The whole set of cgi parameters is as follows:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">
<span class="strong"><strong>db</strong></span> : numeric database name. Default 1000.
</li><li class="listitem">
<span class="strong"><strong>op</strong></span> : either <code class="literal">search</code> or <code class="literal">recids</code>. Here we assume <code class="literal">search</code>,
    will cover <code class="literal">recids</code> later.
</li><li class="listitem">
<span class="strong"><strong>field</strong></span> : field number (0,1,2, etc) to check against the compared value.
</li><li class="listitem">
<span class="strong"><strong>value</strong></span> : value to check the field contents against.
    Examples: value=32, value=sometext.
</li><li class="listitem">
<span class="strong"><strong>type</strong></span> : datatype of the value: null, int, double, str, char or record.
    Guessed from the value by default.
</li><li class="listitem">
<span class="strong"><strong>compare</strong></span> : equal, not_equal, lessthan, greater, ltequal or gtequal.
    Default <code class="literal">equal</code>.
</li><li class="listitem">
<span class="strong"><strong>from</strong></span> : skip initial matching records, start from the result nr given here.
    Default 0.
</li><li class="listitem">
<span class="strong"><strong>count</strong></span> : max number of matching records output. Default 10000.
</li><li class="listitem">
<span class="strong"><strong>depth</strong></span> : max depth of nested trees of records. Default 100, hard limit 10000.
    Set to 0 for hiding all sublists.
    Modify the macro MAX_DEPTH_HARD to change the hard limit.
</li><li class="listitem">
<span class="strong"><strong>format</strong></span> : either <code class="literal">json</code> or <code class="literal">csv</code>. Default <code class="literal">json</code>.
</li><li class="listitem">
<span class="strong"><strong>escape</strong></span> : escaping special characters in json strings,
    either <code class="literal">no</code> (replace nothing) , <code class="literal">url</code> (urlencode %, " and all
    non-printable and non-ascii characters, i.e. under 32 and over 126, to be
    completely ascii-safe) or <code class="literal">json</code> (not ascii-safe: replace only the
    minimal set indicated in the rfc).
    Default <code class="literal">json</code>. NB! this parameter has no effect for csv,
    where only " gets replaced with "".
</li><li class="listitem">
*showid : <code class="literal">yes</code> or <code class="literal">no</code>, if <code class="literal">yes</code>, print the record offset (automatic id) as the
    first element of each record, moving all the other fields one position to the right.
    Default <code class="literal">no</code>.
</li></ul></div><p>All the input values are assumed to be urlencoded.</p><p>The json output is a list of matching records. Each record is also presented as a list.
The list elements are integers, doubles, strings or records (again represented as lists)
pointed to from the field.  Null is printed as an empty list [].</p><p>All the other datatypes, like dates, times, URI-s, strings with a language attribute etc
in WhiteDB are converted to standard strings in a fairly intuitive manner.
Blobs are url-encoded. For csv and too deep json branches the full internal record
is represented by its offset (encoded pointer, i.e. automatic id).</p><p>Notice that for a graph database the json output can be a complex tree of records. Cycles are
possible, but can be inhibited by the depth parameter.</p><p>Errors are reported by printing an error string as a single element of the output list, both
for json and csv, like this:</p><pre class="screen">content-length: 48
content-type: application/json

["unrecognized op: use op=search or op=recids"]</pre><p>On Linux <code class="literal">dserve</code> should be able to free locks and detach the database even in case of
hard errors like segfaults.</p><p>Importantly, you can give several sets of field/value/compare/count parameters to perform a
complex and-query. Example:</p><pre class="literallayout">dserve 'op=search&amp;field=1&amp;value=100&amp;type=int&amp;compare=lessthan&amp;field=2&amp;value=10.3&amp;type=double&amp;compare=greater'</pre><p>In case you use several fields in the query, you have to fill the otherwise optional type
and compare parameters for all the fields indicated. BTW, it is OK to put the same field
into several comparisons.</p><p>You can also have no fields in the query at all. In this case the full database will be traversed
and printed according to the parameters given.</p></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="_query_by_record_id_s"></a>2.2. Query by record id-s</h3></div></div></div><p>The second way to query is to simply indicate a list of record id-s (offsets: encoded record
pointers) like this:</p><pre class="literallayout">dserve 'op=recids&amp;recids=12000,10236,22458'</pre><p>You can learn the record id-s by using the <code class="literal">showid=yes</code> parameter described before.</p><p>The database selection parameter <code class="literal">db</code> and the generic formatting parameters
<code class="literal">depth</code>,<code class="literal">format</code>,<code class="literal">escape</code> and <code class="literal">showid</code> function exactly as described above.</p></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="_good_to_know"></a>2.3. Good to know</h3></div></div></div><p>Things to note and useful code examples in dserve:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">
does not require additional libraries except wgdb
</li><li class="listitem">
uses readlocks, does not use writelocks
</li><li class="listitem">
cgi parameter parsing
</li><li class="listitem">
various printing routines for WhiteDB values
</li><li class="listitem">
text is printed into a an automatically growing string buffer
</li><li class="listitem">
error and timeout handling with signals: when a signal arrives, free the readlock,
  detach database and output ["internal error"] or ["timeout"]. Available on Linux only.
</li></ul></div></div></div></div>
      </div>
    </div>        
  </div>
</div>  

<!-- footer -->

<div class="ofooter">  
 <div class="col-md-12 container ifooter">
  <div id="team">
    <a href="contact.html" style="color: #666666; font-family: 'Roboto'; font-size: 16px;">WhiteDB team 2013</a>
  </div>    
  <p> 
  <div id="gplusone">
    <div class="g-plusone" data-annotation="none" data-size="large" data-expandTo="right"
        data-href="http://www.whitedb.org">
    </div>
  </div>
  <p>
  <div id="twitter">
    <div>
    <a href="https://twitter.com/share" class="twitter-share-button" 
         data-url="http://www.whitedb.org" data-hashtags="whitedb"
         data-text="a fast database library in shared memory">Tweet</a>
    </div>
  </div>
  <div id="facebook">
    <div class="fb-like" data-href="http://www.whitedb.org" 
        data-colorscheme="light" 
        data-layout="box-count" data-action="like" 
        data-show-faces="true" data-send="true">
    </div>
  </div>
  
  </div>  
</div> 

<!-- at-end-scripts -->

<!-- Bootstrap core JavaScript -->

<script src="js/bootstrap.min.js"></script>

<!-- social scripts -->

<script>
// facebook

(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#xfbml=1&appId=168856549986981";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));

// google+ 

(function() {
   var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
   po.src = 'https://apis.google.com/js/client:plusone.js?onload=gplus_render';
   //po.src = 'https://apis.google.com/js/plusone.js?';
   var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
 })();

// twitter 

!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';
  if(!d.getElementById(id)){js=d.createElement(s);js.id=id;
  js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);
  }}(document, 'script', 'twitter-wjs');
    
// google analytics

  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-44786402-1', 'whitedb.org');
  ga('send', 'pageview');

</script>  
  
</body>
</html>
